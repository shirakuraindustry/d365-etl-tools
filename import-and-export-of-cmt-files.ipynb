{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30be53e",
   "metadata": {},
   "source": [
    "Extract the imported zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35fe4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'cmt-files/imported-data\\data-data.zip' does not exist.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = os.path.join('cmt-files/imported-data', f'data-data.zip')\n",
    "extract_dir = 'cmt-files/imported-data'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(zip_path):\n",
    "    print(f\"Error: The file '{zip_path}' does not exist.\")\n",
    "else:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(f\"Extracted files to '{extract_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fce46",
   "metadata": {},
   "source": [
    "To convert data.xml into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c7da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to cmt-files/imported-data/account.parquet\n",
      "Table Name: account\n",
      "name                             record_id accountclassificationcode  \\\n",
      "0     00416cb1-4219-ed11-b83e-000d3acf194f                         1   \n",
      "1     00a3c8ae-4219-ed11-b83e-000d3acedc8d                         1   \n",
      "2     019771ab-4219-ed11-b83e-000d3acf194f                         1   \n",
      "3     01a3c8ae-4219-ed11-b83e-000d3acedc8d                         1   \n",
      "4     029771ab-4219-ed11-b83e-000d3acf194f                         1   \n",
      "..                                     ...                       ...   \n",
      "375   f9a1c8ae-4219-ed11-b83e-000d3acedc8d                         1   \n",
      "376   fa7ccba8-4219-ed11-b83e-000d3acedc8d                         1   \n",
      "377   fdb6b908-ded6-ee11-904c-6045bd540c5a                         1   \n",
      "378   fe406cb1-4219-ed11-b83e-000d3acf194f                         1   \n",
      "379   ff406cb1-4219-ed11-b83e-000d3acf194f                         1   \n",
      "\n",
      "name                             accountid accountnumber accountratingcode  \\\n",
      "0     00416cb1-4219-ed11-b83e-000d3acf194f           NaN                 1   \n",
      "1     00a3c8ae-4219-ed11-b83e-000d3acedc8d           NaN                 1   \n",
      "2     019771ab-4219-ed11-b83e-000d3acf194f           NaN                 1   \n",
      "3     01a3c8ae-4219-ed11-b83e-000d3acedc8d           NaN                 1   \n",
      "4     029771ab-4219-ed11-b83e-000d3acf194f           NaN                 1   \n",
      "..                                     ...           ...               ...   \n",
      "375   f9a1c8ae-4219-ed11-b83e-000d3acedc8d           NaN                 1   \n",
      "376   fa7ccba8-4219-ed11-b83e-000d3acedc8d           NaN                 1   \n",
      "377   fdb6b908-ded6-ee11-904c-6045bd540c5a           NaN                 1   \n",
      "378   fe406cb1-4219-ed11-b83e-000d3acf194f           NaN                 1   \n",
      "379   ff406cb1-4219-ed11-b83e-000d3acf194f           NaN                 1   \n",
      "\n",
      "name                    address1_addressid address1_city address1_composite  \\\n",
      "0     3d735588-7974-4f87-9daa-9e28202bee63           NaN                NaN   \n",
      "1     33e3038b-0059-4e47-b759-97db80f6dd08           NaN                NaN   \n",
      "2     ee15d8ae-0466-4c21-9d5b-6119ae2c13e4           NaN                NaN   \n",
      "3     75abd132-10b6-4ec7-921d-765928804ae0           NaN                NaN   \n",
      "4     0dc2fb89-a628-4545-9f9f-442e98ce1b81           NaN                NaN   \n",
      "..                                     ...           ...                ...   \n",
      "375   d1db9b5d-ad5c-408a-a23a-2795e30e8020           NaN                NaN   \n",
      "376   b1dbf6aa-11dd-437b-bd15-0202ea41bf4c           NaN                NaN   \n",
      "377   42713e98-93cf-4e78-9ca2-4f47cae8593a           NaN                NaN   \n",
      "378   4b713900-470d-479f-99ac-7c0406b29c56           NaN                NaN   \n",
      "379   9f22e537-bad2-45e0-b0ea-3d45df15407d           NaN                NaN   \n",
      "\n",
      "name address1_country address1_latitude  ...  sic statecode statuscode  \\\n",
      "0                 NaN               NaN  ...  NaN         1          2   \n",
      "1                 NaN               NaN  ...  NaN         1          2   \n",
      "2                 NaN               NaN  ...  NaN         1          2   \n",
      "3                 NaN               NaN  ...  NaN         1          2   \n",
      "4                 NaN               NaN  ...  NaN         1          2   \n",
      "..                ...               ...  ...  ...       ...        ...   \n",
      "375               NaN               NaN  ...  NaN         1          2   \n",
      "376               NaN               NaN  ...  NaN         1          2   \n",
      "377               NaN               NaN  ...  NaN         1          2   \n",
      "378               NaN               NaN  ...  NaN         1          2   \n",
      "379               NaN               NaN  ...  NaN         1          2   \n",
      "\n",
      "name telephone1 territorycode tickersymbol  \\\n",
      "0           NaN             1          NaN   \n",
      "1           NaN             1          NaN   \n",
      "2           NaN             1          NaN   \n",
      "3           NaN             1          NaN   \n",
      "4           NaN             1          NaN   \n",
      "..          ...           ...          ...   \n",
      "375         NaN             1          NaN   \n",
      "376         NaN             1          NaN   \n",
      "377         NaN             1          NaN   \n",
      "378         NaN             1          NaN   \n",
      "379         NaN             1          NaN   \n",
      "\n",
      "name                 transactioncurrencyid transactioncurrencyid_name  \\\n",
      "0     5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "1     5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "2     5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "3     5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "4     5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "..                                     ...                        ...   \n",
      "375   5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "376   5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "377   5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "378   5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "379   5888cedb-4416-ed11-b83d-000d3acee53f                          円   \n",
      "\n",
      "name websiteurl yominame  \n",
      "0           NaN      NaN  \n",
      "1           NaN      NaN  \n",
      "2           NaN      NaN  \n",
      "3           NaN      NaN  \n",
      "4           NaN      NaN  \n",
      "..          ...      ...  \n",
      "375         NaN      NaN  \n",
      "376         NaN      NaN  \n",
      "377         NaN      NaN  \n",
      "378         NaN      NaN  \n",
      "379         NaN      NaN  \n",
      "\n",
      "[380 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the XML file path\n",
    "data_file = Path(\"cmt-files/imported-data/data.xml\")\n",
    "\n",
    "# Parse the XML file and extract fields with their parent record IDs\n",
    "def parse_xml_with_all_attributes(file_path):\n",
    "    records = []\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract the name attribute from the entity element\n",
    "    table_name = root.find(\".//entity\").get(\"name\") if root.find(\".//entity\") is not None else None\n",
    "\n",
    "    # Iterate over each <record> element\n",
    "    for record in root.findall(\".//record\"):\n",
    "        record_id = record.get(\"id\")  # Extract the record ID\n",
    "        # Iterate over each <field> within the <record>\n",
    "        for field in record.findall(\"field\"):\n",
    "            field_data = {key: field.get(key) for key in field.keys()}  # Extract all field attributes\n",
    "            field_data[\"record_id\"] = record_id  # Add the parent record ID\n",
    "\n",
    "            # Check if lookupentity attribute exists\n",
    "            if field.get(\"lookupentity\"):\n",
    "                # Add lookupentityname as a separate row\n",
    "                records.append({\n",
    "                    \"record_id\": record_id,\n",
    "                    \"name\": field.get(\"name\") + \"_name\",\n",
    "                    \"value\": field.get(\"lookupentityname\")\n",
    "                })\n",
    "\n",
    "            records.append(field_data)\n",
    "\n",
    "    return pd.DataFrame(records), table_name\n",
    "\n",
    "# Parse the XML and create the DataFrame\n",
    "df, table_name = parse_xml_with_all_attributes(data_file)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_pivoted = df.pivot(index=\"record_id\", columns=\"name\", values=\"value\")\n",
    "\n",
    "# Reset the index if needed\n",
    "df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# Save the DataFrame to a Parquet file\n",
    "if table_name:\n",
    "    parquet_file = f\"cmt-files/imported-data/{table_name}.parquet\"\n",
    "    df_pivoted.to_parquet(parquet_file, engine=\"pyarrow\")\n",
    "    print(f\"DataFrame saved to {parquet_file}\")\n",
    "else:\n",
    "    print(\"Table name is not available. DataFrame not saved.\")\n",
    "\n",
    "# Display the pivoted DataFrame and table name\n",
    "print(f\"Table Name: {table_name}\")\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmt-files\\imported-data\\account.parquet\n",
      "cmt-files\\formatted-data\\account.parquet\n",
      "New records saved to cmt-files\\difference-data\\account.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths for the imported and formatted data folders\n",
    "imported_data_path = Path(f\"cmt-files/imported-data/{table_name}.parquet\")\n",
    "formatted_data_path = Path(f\"cmt-files/formatted-data/{table_name}.parquet\")\n",
    "difference_data_path = Path(f\"cmt-files/difference-data/{table_name}.parquet\")\n",
    "print(imported_data_path)\n",
    "print(formatted_data_path)\n",
    "\n",
    "# Load the DataFrames from the Parquet files\n",
    "if imported_data_path.exists() and formatted_data_path.exists():\n",
    "    imported_df = pd.read_parquet(imported_data_path)\n",
    "    formatted_df = pd.read_parquet(formatted_data_path)\n",
    "\n",
    "    # Ensure both DataFrames have a 'modifiedon' column\n",
    "    if 'modifiedon' in imported_df.columns and 'modifiedon' in formatted_df.columns:\n",
    "        # Convert 'modifiedon' columns to datetime for comparison\n",
    "        imported_df['modifiedon'] = pd.to_datetime(imported_df['modifiedon'])\n",
    "        formatted_df['modifiedon'] = pd.to_datetime(formatted_df['modifiedon'])\n",
    "\n",
    "        # Find records in imported_df that are newer than the latest in formatted_df\n",
    "        latest_modifiedon = formatted_df['modifiedon'].max()\n",
    "        new_records_df = imported_df[imported_df['modifiedon'] > latest_modifiedon]\n",
    "\n",
    "        # Save the new records to the difference-data folder\n",
    "        new_records_df.to_parquet(difference_data_path, engine=\"pyarrow\")\n",
    "        print(f\"New records saved to {difference_data_path}\")\n",
    "    else:\n",
    "        print(\"Error: 'modifiedon' column is missing in one of the DataFrames.\")\n",
    "else:\n",
    "    print(\"Error: One or both Parquet files do not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
